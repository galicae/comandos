{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# util\n",
    "\n",
    "> Collection of helper functions to facilitate plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions in this module depend on `numpy`/`pandas`, `anndata`, and `scanpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from samap.mapping import SAMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "from fastcore.test import *\n",
    "from fastcore.docments import docments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def procrustes(x:str, # input string\n",
    "               appropriate_length:int=50, # desired length\n",
    "               pad_with:str=\" \", # character to pad with\n",
    "               side:str=\"right\" # which side to pad on (\"left\", \"right\")\n",
    "              )->str: # string with desired length\n",
    "    \"A function to regulate string length.\"\n",
    "    if len(x) > appropriate_length:\n",
    "        return x[:appropriate_length]\n",
    "    if len(x) < appropriate_length:\n",
    "        to_pad = appropriate_length - len(x)\n",
    "        pad = \"\".join([pad_with] * to_pad)\n",
    "        if side == \"right\":\n",
    "            x = x + pad\n",
    "        elif side == \"left\":\n",
    "            x = pad + x\n",
    "        else:\n",
    "            print(\"Invalid side argument; returning string as-is.\")\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are primarily going to be working with non-model species, so the gene names will always be of the form\n",
    "\n",
    "`XLOC_123456 | emapper-name-or-description-if-we're-lucky`\n",
    "\n",
    "or something similar. This means that we could have extreme variation in the actual length of a gene \"name\"; this will make it very hard to put gene names on axes as it will distort figure sizes. I wrote a function to either trim or pad strings; even though axis labels are not in monospace fonts, it is much easier to visually reconcile strings with lengths in the same order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_short = 'Niko'\n",
    "just_right = 'Theseus'\n",
    "too_tall = 'The Mountain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert procrustes(just_right, appropriate_length=7) == 'Theseus'\n",
    "assert procrustes(too_short, appropriate_length=7) == 'Niko   '\n",
    "assert procrustes(too_tall, appropriate_length=7) == 'The Mou'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grouped_obs_mean'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def grouped_obs_mean(adata:ad.AnnData, # AnnData object to analyse\n",
    "                        group_key:str, # `.obs` category to group by\n",
    "                        layer:str=None # layer to use. If none, use `.X`\n",
    "                    )->pd.DataFrame: # a groups$\\times$genes dataframe with the average expression\n",
    "    \"Helper function to calculate average expression per group in an `AnnData` object.\"\n",
    "    if layer is not None:\n",
    "        getX = lambda x: x.layers[layer]\n",
    "    else:\n",
    "        getX = lambda x: x.X\n",
    "\n",
    "    grouped = adata.obs.groupby(group_key)\n",
    "    out = pd.DataFrame(\n",
    "        np.zeros((adata.shape[1], len(grouped)), dtype=np.float64),\n",
    "        columns=list(grouped.groups.keys()),\n",
    "        index=adata.var_names,\n",
    "    )\n",
    "\n",
    "    for group, idx in grouped.indices.items():\n",
    "        X = getX(adata[idx])\n",
    "        out[group] = np.ravel(X.mean(axis=0, dtype=np.float64))\n",
    "    return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many tasks in single-cell analysis require us to know the average expression of a gene in a certain\n",
    "group of cells. While `scanpy` _does_ perform that task behind the scenes for, e.g. dotplots, this\n",
    "is not functionality that is exposed to the users. This is an implementation based on [ivirshup's\n",
    "answer](https://github.com/theislab/scanpy/issues/181#issuecomment-534867254) to a scanpy issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#| hide\n",
    "FILE=\"../example_data/hydra.h5ad\"\n",
    "if test -f \"$FILE\"\n",
    "then\n",
    "    echo \"$FILE exists.\"\n",
    "else\n",
    "    cd ..\n",
    "    wget https://zenodo.org/record/8129708/files/example_data.tar.gz\n",
    "    tar -xzf example_data.tar.gz\n",
    "    cd ../scripts\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('../example_data/hydra.h5ad')\n",
    "\n",
    "cluster_means = grouped_obs_mean(adata, group_key='Cluster')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $G$ is the number of genes and $C$ the number of unique clusters in the `group_key`, the returned array should have the shape $G \\times C$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_genes = adata.shape[1]\n",
    "no_clusters = len(np.unique(adata.obs['Cluster']))\n",
    "assert cluster_means.shape == (no_genes, no_clusters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, each column of the array should contain the average detected expression for cells in that cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belong_to_ecEp_SC2 = adata.obs['Cluster'] == 'ecEp_SC2'\n",
    "ecEp_SC2_average = np.mean(adata[belong_to_ecEp_SC2].X, axis=0)\n",
    "ecEp_SC2_average = np.array(ecEp_SC2_average)[0]\n",
    "\n",
    "assert all(np.isclose(cluster_means['ecEp_SC2'], ecEp_SC2_average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def grouped_obs_present(adata, group_key, layer=None):\n",
    "    \"\"\"\n",
    "    Helper function to calculate how many cells express each gene per group in an `AnnData` object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : AnnData\n",
    "        AnnData object to analyse.\n",
    "    group_key : str\n",
    "        `.obs` category to group by.\n",
    "    layer : str, optional\n",
    "        Layer to use. If none, use `.X`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A clusters$\\times$genes dataframe with the number of expressing cells per cluster.\n",
    "    \"\"\"\n",
    "    if layer is not None:\n",
    "        getX = lambda x: x.layers[layer]\n",
    "    else:\n",
    "        getX = lambda x: x.X\n",
    "\n",
    "    grouped = adata.obs.groupby(group_key)\n",
    "    out = pd.DataFrame(\n",
    "        np.zeros((adata.shape[1], len(grouped)), dtype=np.float64),\n",
    "        columns=list(grouped.groups.keys()),\n",
    "        index=adata.var_names,\n",
    "    )\n",
    "\n",
    "    for group, idx in grouped.indices.items():\n",
    "        X = getX(adata[idx])\n",
    "        out[group] = np.ravel((X > 0).sum(axis=0, dtype=np.float64))\n",
    "    return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another critical value to know when making dotplots is the fraction of cells expressing a gene in a certain cluster. Again, `scanpy` performs that task without exposing it to the users. Similar to [`grouped_obs_mean`](#grouped_obs_mean) this is an implementation based on [ivirshup's answer](https://github.com/theislab/scanpy/issues/181#issuecomment-534867254) to a scanpy issue. Here we calculate the sum of cells expressing a gene, a table we can use to calculate the fraction later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_expressing = grouped_obs_present(adata, group_key='Cluster')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $G$ is the number of genes and $C$ the number of unique clusters in the `group_key`, the returned array should have the shape $G \\times C$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_expressing.shape == (no_genes, no_clusters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, each column of the array should contain the percentage of cells expressing each gene in that cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belong_to_ecEp_SC2 = adata.obs['Cluster'] == 'ecEp_SC2'\n",
    "ecEp_SC2_expr = np.sum(adata[belong_to_ecEp_SC2].X>0, axis=0)\n",
    "ecEp_SC2_expr = np.array(ecEp_SC2_expr)[0]\n",
    "\n",
    "assert all(num_expressing['ecEp_SC2'] == ecEp_SC2_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def grouped_obs_percent(adata, group_key, layer=None):\n",
    "    \"\"\"\n",
    "    Helper function to calculate what percentage of cells express each gene per group in an\n",
    "    `AnnData` object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : AnnData\n",
    "        AnnData object to analyse.\n",
    "    group_key : str\n",
    "        `.obs` category to group by.\n",
    "    layer : str, optional\n",
    "        Layer to use. If none, use `.X`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A clusters$\\times$genes dataframe with the percentage of expressing cells per cluster.\n",
    "    \"\"\"\n",
    "    num_expressing = grouped_obs_present(adata, group_key, layer=layer)\n",
    "    no_cells_per_cluster = adata.obs[group_key].value_counts()\n",
    "    return num_expressing / no_cells_per_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the fraction of cells is of course very straightforward once we have counted the number of cells that express the gene as well as the total number of cells in a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_expressing = grouped_obs_percent(adata, group_key='Cluster')\n",
    "# use the counts and number of cells we calculated before\n",
    "frac_ecEp_SC2 = ecEp_SC2_expr / np.sum(belong_to_ecEp_SC2)\n",
    "\n",
    "assert all(np.isclose(frac_expressing['ecEp_SC2'], frac_ecEp_SC2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highlighting clusters\n",
    "\n",
    "Dimensionality reduction plots can often be rather busy, and searching for the correct cluster can\n",
    "be a bit of a hassle. It would be great if we could highlight the cluster of interest without losing\n",
    "the rest of the clustering information; for instance by drawing a circle around the cluster to\n",
    "highlight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_center(coords):\n",
    "    \"\"\"\n",
    "    A function that estimates a Gaussian probability density for the input data and returns the\n",
    "    mode. From https://stackoverflow.com/a/60185876.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coords : np.ndarray\n",
    "        A 2D array with X, Y-coordinates from xs, ys.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The X-coordinate of the mode.\n",
    "    float\n",
    "        The Y-coordinate of the mode.\n",
    "    \"\"\"\n",
    "    kernel = gaussian_kde(coords.T)\n",
    "    min_x, min_y = np.min(coords, axis=0)\n",
    "    max_x, max_y = np.max(coords, axis=0)\n",
    "    grid_xs, grid_ys = np.mgrid[min_x:max_x:50j, min_y:max_y:50j]\n",
    "    positions = np.vstack(\n",
    "        [grid_xs.ravel(), grid_ys.ravel()]\n",
    "    )  # 2-dim array with X, Y-coordinates from xs, ys\n",
    "    Z = np.reshape(kernel(positions).T, grid_xs.shape)  # get densities\n",
    "\n",
    "    idx = np.unravel_index(np.argmax(Z), Z.shape)\n",
    "    return grid_xs[idx], grid_ys[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A heuristic to achieve this is to pretend the cluster points are a Gaussian cloud on\n",
    "UMAP/tSNE/PCA/\\<your favorite embedding\\> space, and take the position with the highest density (the\n",
    "mode of the 2D distribution). This function is inspired from a [StackOverflow\n",
    "answer](https://stackoverflow.com/a/60185876), and mostly a wrapper around the [Gaussian\n",
    "KDE](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html) function\n",
    "from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2D Gaussian dataset\n",
    "x = np.random.normal(loc=2, scale=1, size=1000)\n",
    "y = np.random.normal(loc=-2, scale=1, size=1000)\n",
    "\n",
    "coords = np.array([x, y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_center = find_center(coords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd expect the mode of the kernel density estimate to be very close to the true mean of the data.\n",
    "Since this is for plotting purposes we don't need to be extremely specific. See\n",
    "`plot:highlighted_dimplot` for a demonstration of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(coords_center[0], 2, rtol=0.2)\n",
    "assert np.isclose(coords_center[1], -2, rtol=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fine_to_coarse(sm, species, fine, coarse, plot=sc.pl.umap, include_coarse=False):\n",
    "    \"\"\"\n",
    "    Extract the mapping of fine to coarse clusters from a SAMap object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sm : sm.maps.SAMAP\n",
    "        SAMAP object to process.\n",
    "    species : str\n",
    "        Species ID of the correct SAM object.\n",
    "    fine : str\n",
    "        Fine clustering slot name.\n",
    "    coarse : str\n",
    "        Coarse clustering slot name.\n",
    "    plot : function, optional\n",
    "        Plotting function to use; this will correctly set the colors (default: `sc.pl.umap`).\n",
    "    include_coarse : bool, optional\n",
    "        If True, preface the fine cluster names with the coarse cluster names (default: `False`).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fine_to_coarse: pd.DataFrame\n",
    "        A dataframe with the mapping of fine to coarse clusters.\n",
    "    lut: dict\n",
    "        A dictionary with the colors for each coarse cluster.\n",
    "    handles: list\n",
    "        A list of `matplotlib.patches.Patch` objects with the colors for each coarse cluster.\n",
    "    \"\"\"\n",
    "    fine_to_coarse = (\n",
    "        sm.sams[species]\n",
    "        .adata.obs[[fine, coarse]]\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    plot(sm.sams[species].adata, color=coarse)\n",
    "\n",
    "    lut = dict(\n",
    "        zip(\n",
    "            sm.sams[species].adata.obs[coarse].cat.categories,\n",
    "            sm.sams[species].adata.uns[coarse + \"_colors\"],\n",
    "        )\n",
    "    )\n",
    "    handles = [Patch(facecolor=lut[name]) for name in lut]\n",
    "    if include_coarse:\n",
    "        fine_to_coarse[fine] = (\n",
    "            species\n",
    "            + \"_\"\n",
    "            + fine_to_coarse[coarse].astype(str)\n",
    "            + \"_\"\n",
    "            + fine_to_coarse[fine].astype(str)\n",
    "        )\n",
    "    else:\n",
    "        fine_to_coarse[fine] = species + \"_\" + fine_to_coarse[fine].astype(str)\n",
    "    return fine_to_coarse, lut, handles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
