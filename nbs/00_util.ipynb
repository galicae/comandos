{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# util\n",
    "\n",
    "> Collection of helper functions to facilitate plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from urllib.error import HTTPError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scanpy as sc\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.stats import gaussian_kde\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from fastcore.docments import docments\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "if \"EXAMPLE_DATA_PATH\" not in os.environ.keys():\n",
    "    os.environ[\n",
    "        \"EXAMPLE_DATA_PATH\"\n",
    "    ] = \"/Users/npapadop/Documents/repos/comandos/example_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def procrustes(\n",
    "    x: str,  # input string\n",
    "    appropriate_length: int = 50,  # desired length\n",
    "    pad_with: str = \" \",  # character to pad with\n",
    "    side: str = \"right\",  # which side to pad on (\"left\", \"right\")\n",
    ") -> str:  # string with desired length\n",
    "    \"A function to regulate string length.\"\n",
    "    if len(x) > appropriate_length:\n",
    "        return x[:appropriate_length]\n",
    "    if len(x) < appropriate_length:\n",
    "        to_pad = appropriate_length - len(x)\n",
    "        pad = \"\".join([pad_with] * to_pad)\n",
    "        if side == \"right\":\n",
    "            x = x + pad\n",
    "        elif side == \"left\":\n",
    "            x = pad + x\n",
    "        else:\n",
    "            print(\"Invalid side argument; returning string as-is.\")\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are primarily going to be working with non-model species, so the gene names will always be of the form\n",
    "\n",
    "`XLOC_123456 | emapper-name-or-description-if-we're-lucky`\n",
    "\n",
    "or something similar. This means that we could have extreme variation in the actual length of a gene \"name\"; this will make it very hard to put gene names on axes as it will distort figure sizes. I wrote a function to either trim or pad strings; even though axis labels are not in monospace fonts, it is much easier to visually reconcile strings with lengths in the same order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_short = \"Niko\"\n",
    "just_right = \"Theseus\"\n",
    "too_tall = \"The Mountain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert procrustes(just_right, appropriate_length=7) == \"Theseus\"\n",
    "assert procrustes(too_short, appropriate_length=7) == \"Niko   \"\n",
    "assert procrustes(too_tall, appropriate_length=7) == \"The Mou\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def grouped_obs_mean(\n",
    "    adata: ad.AnnData,  # AnnData object to analyse\n",
    "    group_key: str,  # `.obs` category to group by\n",
    "    layer: Union[str, None] = None,  # layer to use. If none, use `.X`\n",
    ") -> pd.DataFrame:  # a groups$\\times$genes dataframe with the average expression\n",
    "    \"Helper function to calculate average expression per group in an `AnnData` object.\"\n",
    "    if layer is not None:\n",
    "        getX = lambda x: x.layers[layer]\n",
    "    else:\n",
    "        getX = lambda x: x.X\n",
    "\n",
    "    grouped = adata.obs.groupby(group_key, observed=False)\n",
    "    out = pd.DataFrame(\n",
    "        np.zeros((adata.shape[1], len(grouped)), dtype=np.float64),\n",
    "        columns=list(grouped.groups.keys()),\n",
    "        index=adata.var_names,\n",
    "    )\n",
    "\n",
    "    for group, idx in grouped.indices.items():\n",
    "        X = getX(adata[idx])\n",
    "        out[group] = np.ravel(X.mean(axis=0, dtype=np.float64))\n",
    "    return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many tasks in single-cell analysis require us to know the average expression of a gene in a certain\n",
    "group of cells. While `scanpy` _does_ perform that task behind the scenes for, e.g. dotplots, this\n",
    "is not functionality that is exposed to the users. This is an implementation based on [ivirshup's\n",
    "answer](https://github.com/theislab/scanpy/issues/181#issuecomment-534867254) to a scanpy issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(os.environ[\"EXAMPLE_DATA_PATH\"] + \"hydra.h5ad\")\n",
    "\n",
    "cluster_means = grouped_obs_mean(adata, group_key=\"Cluster\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $G$ is the number of genes and $C$ the number of unique clusters in the `group_key`, the returned array should have the shape $G \\times C$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_genes = adata.shape[1]\n",
    "no_clusters = len(np.unique(adata.obs[\"Cluster\"]))\n",
    "assert cluster_means.shape == (no_genes, no_clusters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, each column of the array should contain the average detected expression for cells in that cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belong_to_ecEp_SC2 = adata.obs[\"Cluster\"] == \"ecEp_SC2\"\n",
    "ecEp_SC2_average = np.mean(adata[belong_to_ecEp_SC2].X, axis=0)\n",
    "ecEp_SC2_average = np.array(ecEp_SC2_average)[0]\n",
    "\n",
    "assert all(np.isclose(cluster_means[\"ecEp_SC2\"], ecEp_SC2_average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def grouped_obs_present(adata, group_key, layer: Union[str, None] = None):\n",
    "    \"\"\"\n",
    "    Helper function to calculate how many cells express each gene per group in an `AnnData` object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : AnnData\n",
    "        AnnData object to analyse.\n",
    "    group_key : str\n",
    "        `.obs` category to group by.\n",
    "    layer : Union[str, None], optional\n",
    "        Layer to use. If none, use `.X`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A clusters$\\times$genes dataframe with the number of expressing cells per cluster.\n",
    "    \"\"\"\n",
    "    if layer is not None:\n",
    "        getX = lambda x: x.layers[layer]\n",
    "    else:\n",
    "        getX = lambda x: x.X\n",
    "\n",
    "    grouped = adata.obs.groupby(group_key, observed=False)\n",
    "    out = pd.DataFrame(\n",
    "        np.zeros((adata.shape[1], len(grouped)), dtype=np.float64),\n",
    "        columns=list(grouped.groups.keys()),\n",
    "        index=adata.var_names,\n",
    "    )\n",
    "\n",
    "    for group, idx in grouped.indices.items():\n",
    "        X = getX(adata[idx])\n",
    "        out[group] = np.ravel((X > 0).sum(axis=0, dtype=np.float64))\n",
    "    return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another critical value to know when making dotplots is the fraction of cells expressing a gene in a certain cluster. Again, `scanpy` performs that task without exposing it to the users. Similar to [`grouped_obs_mean`](#grouped_obs_mean) this is an implementation based on [ivirshup's answer](https://github.com/theislab/scanpy/issues/181#issuecomment-534867254) to a scanpy issue. Here we calculate the sum of cells expressing a gene, a table we can use to calculate the fraction later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_expressing = grouped_obs_present(adata, group_key=\"Cluster\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $G$ is the number of genes and $C$ the number of unique clusters in the `group_key`, the returned array should have the shape $G \\times C$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_expressing.shape == (no_genes, no_clusters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, each column of the array should contain the percentage of cells expressing each gene in that cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belong_to_ecEp_SC2 = adata.obs[\"Cluster\"] == \"ecEp_SC2\"\n",
    "ecEp_SC2_expr = np.sum(adata[belong_to_ecEp_SC2].X > 0, axis=0)\n",
    "ecEp_SC2_expr = np.array(ecEp_SC2_expr)[0]\n",
    "\n",
    "assert all(num_expressing[\"ecEp_SC2\"] == ecEp_SC2_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def grouped_obs_percent(adata, group_key, layer: Union[str, None] = None):\n",
    "    \"\"\"\n",
    "    Helper function to calculate what percentage of cells express each gene per group in an\n",
    "    `AnnData` object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : AnnData\n",
    "        AnnData object to analyse.\n",
    "    group_key : str\n",
    "        `.obs` category to group by.\n",
    "    layer : str, optional\n",
    "        Layer to use. If none, use `.X`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A clusters$\\times$genes dataframe with the percentage of expressing cells per cluster.\n",
    "    \"\"\"\n",
    "    num_expressing = grouped_obs_present(adata, group_key, layer=layer)\n",
    "    no_cells_per_cluster = adata.obs[group_key].value_counts()\n",
    "    return num_expressing / no_cells_per_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the fraction of cells is of course very straightforward once we have counted the number of cells that express the gene as well as the total number of cells in a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_expressing = grouped_obs_percent(adata, group_key=\"Cluster\")\n",
    "# use the counts and number of cells we calculated before\n",
    "frac_ecEp_SC2 = ecEp_SC2_expr / np.sum(belong_to_ecEp_SC2)\n",
    "\n",
    "assert all(np.isclose(frac_expressing[\"ecEp_SC2\"], frac_ecEp_SC2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When visualising gene expression in the context of single-cell RNA-seq comparisons between species,\n",
    "absolute expression values are meaningless, as there are too many factors that determine them that\n",
    "we can not account for. It is sometimes more informative to look at the relative expression of a \n",
    "gene within the organism, i.e. to look at it in terms of min/max expression.\n",
    "\n",
    "Scanpy does not have a provision for this, so here is a small utility function that does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def rescale(\n",
    "        x: pd.DataFrame,\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rescale a dataframe so that row values are in the range [0, 1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : pd.DataFrame\n",
    "        A two-dimensional array to rescale; preferably the output of `grouped_obs_mean`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        the rescaled dataframe.\n",
    "    \"\"\"\n",
    "    rescaled = (x.T - x.min(axis=1)) / (x.max(axis=1) - x.min(axis=1))\n",
    "    return rescaled.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highlighting clusters\n",
    "\n",
    "Dimensionality reduction plots can often be rather busy, and searching for the correct cluster can\n",
    "be a bit of a hassle. It would be great if we could highlight the cluster of interest without losing\n",
    "the rest of the clustering information; for instance by drawing a circle around the cluster to\n",
    "highlight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def find_center(coords):\n",
    "    \"\"\"\n",
    "    A function that estimates a Gaussian probability density for the input data and returns the\n",
    "    mode. From https://stackoverflow.com/a/60185876.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coords : np.ndarray\n",
    "        A 2D array with X, Y-coordinates from xs, ys.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The X-coordinate of the mode.\n",
    "    float\n",
    "        The Y-coordinate of the mode.\n",
    "    \"\"\"\n",
    "    kernel = gaussian_kde(coords.T)\n",
    "    min_x, min_y = np.min(coords, axis=0)\n",
    "    max_x, max_y = np.max(coords, axis=0)\n",
    "    grid_xs, grid_ys = np.mgrid[min_x:max_x:50j, min_y:max_y:50j]\n",
    "    positions = np.vstack(\n",
    "        [grid_xs.ravel(), grid_ys.ravel()]\n",
    "    )  # 2-dim array with X, Y-coordinates from xs, ys\n",
    "    Z = np.reshape(kernel(positions).T, grid_xs.shape)  # get densities\n",
    "\n",
    "    idx = np.unravel_index(np.argmax(Z), Z.shape)\n",
    "    return grid_xs[idx], grid_ys[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A heuristic to achieve this is to pretend the cluster points are a Gaussian cloud on\n",
    "UMAP/tSNE/PCA/\\<your favorite embedding\\> space, and take the position with the highest density (the\n",
    "mode of the 2D distribution). This function is inspired from a [StackOverflow\n",
    "answer](https://stackoverflow.com/a/60185876), and mostly a wrapper around the [Gaussian\n",
    "KDE](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html) function\n",
    "from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random number generator\n",
    "rng = np.random.default_rng(42)\n",
    "# create a 2D Gaussian dataset\n",
    "x = rng.normal(loc=2, scale=1, size=2000)\n",
    "y = rng.normal(loc=-2, scale=1, size=2000)\n",
    "\n",
    "coords = np.array([x, y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_center = find_center(coords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd expect the mode of the kernel density estimate to be very close to the true mean of the data.\n",
    "Since this is for plotting purposes we don't need to be extremely specific. See\n",
    "`plot:highlighted_dimplot` for a demonstration of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(coords_center[0], 2, rtol=0.2)\n",
    "assert np.isclose(coords_center[1], -2, rtol=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def map_fine_to_coarse(\n",
    "    sm, species, fine, coarse=None, plot=sc.pl.umap, include_coarse=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract the mapping of fine to coarse clusters from a SAMap object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sm : sm.maps.SAMAP\n",
    "        SAMAP object to process.\n",
    "    species : str\n",
    "        Species ID of the correct SAM object.\n",
    "    fine : str\n",
    "        Fine clustering slot name.\n",
    "    coarse : str, optional\n",
    "        Coarse clustering slot name. If None, use the same as `fine`, mapping each cluster to\n",
    "        itself. (default: `None`).\n",
    "    plot : function, optional\n",
    "        Plotting function to use; this will correctly set the colors (default: `sc.pl.umap`).\n",
    "    include_coarse : bool, optional\n",
    "        If True, preface the fine cluster names with the coarse cluster names (default: `False`).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fine_to_coarse: pd.DataFrame\n",
    "        A dataframe with the mapping of fine to coarse clusters.\n",
    "    lut: dict\n",
    "        A dictionary with the colors for each coarse cluster.\n",
    "    handles: list\n",
    "        A list of `matplotlib.patches.Patch` objects with the colors for each coarse cluster.\n",
    "    \"\"\"\n",
    "    if coarse is None:\n",
    "        coarse = fine\n",
    "\n",
    "    fine_to_coarse = (\n",
    "        sm.sams[species]\n",
    "        .adata.obs[[fine, coarse]]\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    plt.ioff()\n",
    "    _fig = plot(sm.sams[species].adata, color=coarse, return_fig=True)\n",
    "    plt.close(_fig)\n",
    "    plt.ion()\n",
    "\n",
    "    lut = dict(\n",
    "        zip(\n",
    "            sm.sams[species].adata.obs[coarse].cat.categories,\n",
    "            sm.sams[species].adata.uns[coarse + \"_colors\"],\n",
    "        )\n",
    "    )\n",
    "    handles = [Patch(facecolor=lut[name]) for name in lut]\n",
    "    if include_coarse:\n",
    "        fine_to_coarse[fine] = (\n",
    "            species\n",
    "            + \"_\"\n",
    "            + fine_to_coarse[coarse].astype(str)\n",
    "            + \"_\"\n",
    "            + fine_to_coarse[fine].astype(str)\n",
    "        )\n",
    "    else:\n",
    "        fine_to_coarse[fine] = species + \"_\" + fine_to_coarse[fine].astype(str)\n",
    "    return fine_to_coarse, lut, handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def collapse_unrelated_clusters(\n",
    "    adata: ad.AnnData, cluster: str, fine: str, coarse: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This function collapses unrelated clusters by identifying a major cluster category based on the\n",
    "    `coarse` column. It then assigns the major cluster category to all unrelated clusters in the\n",
    "    `fine` column. The resulting collapsed cluster information is stored in a new column named `fine\n",
    "    + \"_collapsed\"`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : ad.AnnData\n",
    "        The annotation data containing the clusters to be collapsed.\n",
    "    cluster : str\n",
    "        The cluster identifier within the `fine` column that needs to be collapsed.\n",
    "    fine : str\n",
    "        The column name representing the fine-grained clustering.\n",
    "    coarse : str\n",
    "        The column name representing the coarse-grained clustering.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Modifies\n",
    "    -------\n",
    "    Adds a new column to `adata.obs` named `fine + \"_collapsed\"` that contains the collapsed cluster\n",
    "    information.\n",
    "    \"\"\"\n",
    "    cluster_members = adata.obs[fine] == cluster\n",
    "    major_cluster_category = adata.obs[coarse][cluster_members].value_counts().index[0]\n",
    "\n",
    "    major_category_members = np.array(adata.obs[coarse] == major_cluster_category)\n",
    "\n",
    "    summary = adata.obs[coarse].astype(str).values\n",
    "    summary[major_category_members] = adata.obs[fine][major_category_members].values\n",
    "    adata.obs[fine + \"_collapsed\"] = summary\n",
    "    adata.obs[fine + \"_collapsed\"] = adata.obs[fine + \"_collapsed\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.environ[\"EXAMPLE_DATA_PATH\"] + \"hypl.pkl\", \"rb\")\n",
    "sm = pickle.load(file)\n",
    "\n",
    "sm.sams[\"hy\"].adata.obs[\"coarse\"] = (\n",
    "    sm.sams[\"hy\"].adata.obs[\"Cluster\"].str.split(\"_\").str[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_unrelated_clusters(sm.sams[\"hy\"].adata, \"ecEp_SC2\", \"Cluster\", \"coarse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ecEp_SC2', 'ecEp_SC3', 'ecEp_bat1(mp)', 'ecEp_bat2(mp)', 'ecEp_bd',\n",
       "       'ecEp_head', 'ecEp_nem1(pd)', 'ecEp_nem2(id)', 'enEp_SC1', 'enEp_SC2',\n",
       "       'enEp_SC3', 'enEp_foot', 'enEp_head', 'enEp_nem1(pd)', 'enEp_nem2(pd)',\n",
       "       'enEp_tent', 'enEp_tent(pd)', 'i_SC', 'i_fmgl1', 'i_fmgl2_nurse',\n",
       "       'i_gmgc', 'i_mgl', 'i_nb1', 'i_nb2', 'i_nb3', 'i_nb4', 'i_nc1', 'i_nc2',\n",
       "       'i_nc3', 'i_nc4', 'i_nc5', 'i_nc6', 'i_nc7', 'i_nc8', 'i_nc_gc_prog',\n",
       "       'i_nc_prog', 'i_nem', 'i_smgc1', 'i_smgc2', 'i_zmg1', 'i_zmg2', 'nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.sams[\"hy\"].adata.obs[\"Cluster\"].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ecEp_SC2', 'ecEp_SC3', 'ecEp_bat1(mp)', 'ecEp_bat2(mp)', 'ecEp_bd',\n",
       "       'ecEp_head', 'ecEp_nem1(pd)', 'ecEp_nem2(id)', 'enEp', 'i', 'nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.sams[\"hy\"].adata.obs[\"Cluster_collapsed\"].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all subclusters in the `\"ecEP\"` group are still visible, but all other clusters are\n",
    "subsumed by their coarse cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
